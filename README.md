# Fraud-Detection-Project-Insurance-Claims-Dataiku-DSS
# ğŸš¨ Fraud Detection Project â€“ Insurance Claims (Dataiku DSS)

## ğŸ§  Goal
Build a binary classification model to predict if a customer is likely to commit fraud based on historical insurance data, customer profiles, contracts, and location data.

---

## ğŸ“ Data Sources

| File                  | Description                                |
|-----------------------|--------------------------------------------|
| `Contracts.xlsx`      | Insurance contract data                    |
| `Customers.xlsx`      | Customer demographic & profile info        |
| `Historical_Claims.xlsx` | Past claims history, including fraud labels |
| `Departements.xlsx`   | Geographic data (regions, departments)     |

---

## ğŸ§± Workflow Overview (Dataiku)

### 1.  **Data Joining**
- Join `Contracts` with `Customers`
- Add `Historical_Claims` (to create the target variable)
- Enrich with `Departements` to include geographic context

### 2. **Data Preparation**
- Clean & normalize numerical features
- Encode categorical variables with dummy encoding
- Reject IDs and irrelevant features (e.g., litigation_flag)

### 3.  **Target Variable**
- A new binary column `is_fraud` is created:
  - 1 â†’ Fraudulent customer
  - 0 â†’ Non-fraudulent

### 4.  **Train / Test Split**
- Dataset split into `Train_Data` and `Test_Data` (80/20)
- Random sampling used for unbiased split

### 5. âš–**Oversampling**
- SMOTE technique applied on the training set (`Train_Data`) to balance fraud vs. non-fraud cases (50/50)

### 6.  **Machine Learning**
- Algorithms used:
  - Random Forest ğŸŒ²
  - Logistic Regression ğŸ“Š
  - Gradient Boosting ğŸ“ˆ
  - Support Vector Machine (SVM) ğŸ’¡

- Feature handling:
  - Avg-std rescaling for numerical variables
  - Dummy encoding for categorical variables

### 7. **Model Evaluation**
- Evaluation metrics:
  - AUC ROC
  - Precision, Recall
  - Confusion matrix
- Best model selected based on balance between performance and interpretability

---

##  Outputs

| Output Dataset       | Description                         |
|----------------------|-------------------------------------|
| `Oversampling_Data`  | Balanced dataset used for modeling  |
| `Test_Data`          | Held-out test data (untouched)      |
| `Predict fraud (binary)` | Visual analysis + trained models |

---

##  Next Steps
- Deploy the best model for scoring in production
- Set up automatic retraining with updated claims data
- Build dashboard for live fraud monitoring

---

##  Author
Hoda â€“ Junior Data Scientist  
Project built on **Dataiku DSS**  
